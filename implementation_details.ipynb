{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CENG796 Term Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper: Conditional Text Image Generation with Diffusion Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors: Yuanzhi Zhu, Zhaohai Li, Tianwei Wang, Mengchao He, Cong Yao**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Project Group 8a-**\n",
    "**Mehmet Görkem Yiğit: e252220@metu.edu.tr**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Summary of the Paper:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper, written by Zhu et. al., discusses the use of diffusion models for generating text images, proposing a model named Conditional\n",
    "Text Image Generation with Diffusion Models (CTIG-DM). The model utilizes three condition vectors; being image condition (about the visual), text condition (about the textual content) and style condition (about the style of the writer), to control the attribute of the generated images. The paper outlines four generation modes: synthesis, augmentation, recovery, and imitation. The model shows an outstanding performance generating OOV (out-of-vocabulary) words and adapting different domains. The CTIG-DM method outperforms state-of-the-art techniques in both image quality and recognition performance enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![Model Image](./model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Utilized Vectors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "c_i = AttnPool(F_{enc}(I) + Emb(P_i)),\n",
    "$$\n",
    "$$\n",
    "c_t = \\text{Proj}(W_cT + \\text{Emb}(P_t)),\n",
    "$$\n",
    "$$\n",
    "c_s = Proj(Emb(S))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where \\\n",
    "--- $F_{enc}$ represents a feature extractor of a pre-trained text recognizer. \\\n",
    "--- $P_i$ denotes the index of the encoded image patches. \\\n",
    "--- Emb is the embedding function, encoding $P_i$ to obtain positional embeddings. \\\n",
    "--- $W_c$ stands for the classifier weights of the pre-trained text recognizer. \\\n",
    "--- T is the one-hot encoding of the characters in the text. \\\n",
    "--- $P_t$ is the index of characters in the text. \\\n",
    "--- Proj is used for unifying the vector sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diffusion Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$I_{n+1} = I_{n} + \\epsilon$$\n",
    "$$ L = || \\epsilon - \\epsilon_{\\theta} ([c_i, c_t, c_s], I_{n+1})||^2$$\n",
    "Where \\\n",
    "--- $\\epsilon$ is the Gaussian noise. \\\n",
    "--- L is the squared error loss. \\\n",
    "Notice that given the calculation step, L can be directly calculated by the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Generation Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$I_{n' + 1} = I_{n'} - \\epsilon_{\\theta}(\\textbf{c}, I_{n'})$$\n",
    "Where \\\n",
    "--- $\\textbf{c}$ stands for the different settings of proposed conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning! Creating a new Python environment is recommended.\n",
    "**Creating and activating a conda environment:**\n",
    "\n",
    "conda create --name <name_of_your_environment> \\\n",
    "conda activate <name_of_your_environment>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Setting up the Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!bash datasets.sh"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
